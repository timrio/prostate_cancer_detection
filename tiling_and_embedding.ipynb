{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiling and Embeddings notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook helps you:\n",
    "* exploring the data set\n",
    "* computing and saving the tiles from the WSI image\n",
    "* computing and saving the embeddings from the tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.add_dll_directory(\"C:\\\\Users\\\\33631\\\\Desktop\\\\openslide-win64-20171122\\\\bin\")\n",
    "import openslide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "import openslide\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.filters import threshold_otsu\n",
    "import re\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch import LongTensor as LongTensor\n",
    "from torch import FloatTensor as FloatTensor\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_path = \"Data/raw_data/train.csv\"\n",
    "test_set_path = \"Data/raw_data/test.csv\"\n",
    "test_images_folder = \"Data/raw_data/test/test/\"\n",
    "train_images_folder = \"Data/raw_data/train/train/\"\n",
    "train_mask_folder = \"Data/raw_data/train_label_masks/train_label_masks/\"\n",
    "\n",
    "\n",
    "train_tiles_folder = \"Data/processed_data/train_tiles_grid/\"\n",
    "test_tiles_folder = \"Data/processed_data/test_tiles_grid/\"\n",
    "train_tiles_folder_encoding = \"Data/processed_data/train_tiles_encoding_grid/\"\n",
    "test_tiles_folder_encoding = \"Data/processed_data/test_tiles_encoding_grid/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usefull stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = matplotlib.colors.ListedColormap(['black', 'gray', 'green', 'yellow', 'orange', 'red'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(train_set_path)\n",
    "test_set = pd.read_csv(test_set_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the correspondance between isup and gleason\n",
    "(train_set[['isup_grade','gleason_score']]\n",
    "    .groupby('isup_grade')\n",
    "    .agg({'gleason_score': lambda x: x.unique()})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count isup grades\n",
    "(train_set[['isup_grade','gleason_score']]\n",
    "    .groupby('isup_grade')\n",
    "    .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image provider\n",
    "(train_set[['data_provider','gleason_score']]\n",
    "    .groupby('data_provider')\n",
    "    .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_mask_and_image(id, level = 3): \n",
    "    \"\"\"\n",
    "    function to plot images and masks\n",
    "    \"\"\"\n",
    "    line = train_set.iloc[id]\n",
    "\n",
    "    data_provider = line.data_provider\n",
    "    isup_grade = line.isup_grade\n",
    "    gleason_score = line.gleason_score\n",
    "    image_id = line.image_id\n",
    "\n",
    "    image = openslide.OpenSlide(train_images_folder+image_id+'.tiff')\n",
    "    print(image.level_dimensions)\n",
    "    image_data = image.read_region((0,0), image.level_count - 1, image.level_dimensions[-1])\n",
    "    try:\n",
    "        mask = openslide.OpenSlide(train_mask_folder+image_id+'.tiff')\n",
    "        mask_data = mask.read_region((0,0), mask.level_count - 1, mask.level_dimensions[-1])\n",
    "    except:\n",
    "        print('no mask for this image')\n",
    "        mask = None\n",
    "        mask_data = None\n",
    "\n",
    "\n",
    "    fig, axes = plt.subplots(1,2, figsize=(8,8))\n",
    "    axes[0].imshow(image_data)\n",
    "    axes[1].imshow(np.asarray(mask_data)[:,:,0], cmap=cmap, interpolation='nearest', vmin=0, vmax=5)\n",
    "\n",
    "    title = f\"gleason score: {gleason_score} - isup grade: {isup_grade} \\n data provider: {data_provider}\"\n",
    "    fig.suptitle(title, fontsize=14)\n",
    "    \n",
    "    mask.close()\n",
    "    image.close()\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_mask_and_image(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_mask_and_image(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_mask_and_image(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from histolab.tiler import RandomTiler, GridTiler\n",
    "from histolab.slide import Slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tiles(df, folder_dest, folder_source, tile_shape = 224, level = 0, n_tiles = 128, random = True):\n",
    "    \"\"\"\n",
    "    This function create the tiles from the image in a folder\n",
    "    inputs:\n",
    "        - df: train or test set\n",
    "        - folder dest: where to save the tiles\n",
    "        - folder source: where the tiff images are stored\n",
    "        - tile shape: dimension of the tiles (default: (224, 224))\n",
    "        - level: level on which the tiles are extracted\n",
    "        - number of tiles to extract if random = True\n",
    "        - random: whether to implement random tiling or total grid tiling\n",
    "\n",
    "    \"\"\"\n",
    "    for i in tqdm(range(df.shape[0]), position = 0):\n",
    "        value = df.iloc[i]\n",
    "        id = value.image_id\n",
    "        if os.path.isdir(folder_dest+f\"{id}/\"):\n",
    "            continue\n",
    "        image = Slide(folder_source+id+\".tiff\", processed_path=folder_dest)\n",
    "        if random: \n",
    "            tiles_extractor = RandomTiler(\n",
    "                        tile_size=(tile_shape,tile_shape),\n",
    "                        level=level,\n",
    "                        n_tiles=n_tiles,\n",
    "                        seed=42,\n",
    "                        check_tissue=True, # default\n",
    "                        tissue_percent=80.0, # default\n",
    "                        prefix=f'{id}/', # save tiles in the \"random\" subdirectory of slide's processed_path\n",
    "                        suffix=\".png\" # default\n",
    "                    )\n",
    "        else:\n",
    "            tiles_extractor = GridTiler(\n",
    "                        tile_size=(tile_shape,tile_shape),\n",
    "                        level=level,\n",
    "                        check_tissue=True, # default\n",
    "                        tissue_percent=90.0, # default\n",
    "                        pixel_overlap = 0, \n",
    "                        prefix=f'{id}/', # save tiles in the \"random\" subdirectory of slide's processed_path\n",
    "                        suffix=\".png\" # default\n",
    "                    )\n",
    "\n",
    "        tiles_extractor.extract(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiles encoding functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tiles_coords(img_name):\n",
    "    \"\"\"\n",
    "    extract tile coordinate from the file name\n",
    "    \"\"\"\n",
    "    exp = '([0-9]*)-([0-9]*)-([0-9]*)-([0-9]*).png$'\n",
    "    match = re.search(exp, img_name)\n",
    "    x_ul_wsi = match[1]\n",
    "    y_ul_wsi = match[2]\n",
    "    x_br_wsi = match[3]\n",
    "    y_br_wsi = match[4]\n",
    "    return(int(x_ul_wsi),int(y_ul_wsi), int(x_br_wsi),int(y_br_wsi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define encoder model\n",
    "# we took efficientNetB2 for its good performances and for its relative light weight\n",
    "encoder = models.efficientnet_b2(pretrained=True)\n",
    "encoder = nn.Sequential(*list(encoder.children()))[:-1].eval().to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_tiles(df, source_dir, dest_dir, encoder):\n",
    "    \"\"\"\n",
    "    this fucntion compute and save the emebddings for all the tiles in an image folder\n",
    "    inputs:\n",
    "        - df: test or train data set\n",
    "        - source dire: directory path containing the tiles\n",
    "        - desd_r: where to save the embeddings\n",
    "        - encoder: model to encode the tiles\n",
    "    \"\"\"\n",
    "    for i in tqdm(range(df.shape[0]), position = 0):\n",
    "        value = df.iloc[i]\n",
    "        image_id = value.image_id\n",
    "        if os.path.isdir(dest_dir+f'{image_id}.pkl'):\n",
    "            continue\n",
    "        # compute file\n",
    "        image_folder = source_dir+image_id+'/'\n",
    "        # pick images to put in the bag randomly\n",
    "        tiles_list = np.array(os.listdir(image_folder))\n",
    "        encoding_dict = {}\n",
    "        for img_name in tiles_list:\n",
    "            img_path = image_folder+img_name\n",
    "            x_ul_wsi,y_ul_wsi, x_br_wsi,y_br_wsi = extract_tiles_coords(img_name)\n",
    "            # get image\n",
    "            tile_image = np.array(Image.open(img_path))\n",
    "            # convert to RGB\n",
    "            tile_image = Image.fromarray(tile_image)\n",
    "            tile_image = tile_image.convert('RGB')\n",
    "            # to 0/1 range\n",
    "            tile_image = torchvision.transforms.functional.to_tensor(tile_image) # to 0/1 range and permute \n",
    "\n",
    "            normalize = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "            tile_image = normalize(tile_image).unsqueeze(0).to(\"cuda\")\n",
    "            # get encoding\n",
    "            encoding = encoder(tile_image).squeeze(-1).squeeze(-1)[0].cpu().detach().numpy()\n",
    "            # add to dict\n",
    "            encoding_dict[(x_ul_wsi,y_ul_wsi, x_br_wsi,y_br_wsi)] = encoding\n",
    "        pickle.dump(encoding_dict, open(dest_dir+f'{image_id}.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute and encode tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "\n",
    "tiles_shape  = 224\n",
    "level = 0\n",
    "n_tiles = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_tiles(train_set, folder_dest = train_tiles_folder, folder_source=train_images_folder , tile_shape = tiles_shape, level = level, n_tiles = n_tiles, random = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_tiles(train_set, source_dir = train_tiles_folder, dest_dir = train_tiles_folder_encoding, encoder = encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test set\n",
    "create_tiles(test_set, folder_dest = test_tiles_folder, folder_source=test_images_folder , tile_shape = tiles_shape, level = level, n_tiles = n_tiles, random = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train set\n",
    "encode_tiles(test_set, source_dir = test_tiles_folder, dest_dir = test_tiles_folder_encoding, encoder = encoder)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cb07f93c22d8c46e8a2c451ad38041b75d10dd270b337033f28fdbf88ab40e30"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('new_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
